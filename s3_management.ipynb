{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "[]"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#in the project-dev-wm bucket, delete all files in optimised/datedim and optmised/locationdim\n",
                "\n",
                "import boto3\n",
                "\n",
                "s3 = boto3.resource('s3')\n",
                "bucket = s3.Bucket('my-config-bucket-dev')\n",
                "bucket.objects.filter(Prefix='').delete()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "root\n",
                        " |-- date_key: long (nullable = true)\n",
                        " |-- date: string (nullable = true)\n",
                        " |-- day_of_week: long (nullable = true)\n",
                        " |-- day_name: string (nullable = true)\n",
                        " |-- day_of_month: long (nullable = true)\n",
                        " |-- day_of_year: long (nullable = true)\n",
                        " |-- week_of_year: long (nullable = true)\n",
                        " |-- month: long (nullable = true)\n",
                        " |-- month_name: string (nullable = true)\n",
                        " |-- quarter: long (nullable = true)\n",
                        " |-- year: long (nullable = true)\n",
                        " |-- is_weekend: boolean (nullable = true)\n",
                        " |-- is_weekday: boolean (nullable = true)\n",
                        " |-- is_holiday: boolean (nullable = true)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "\n",
                "spark = SparkSession.builder.getOrCreate()\n",
                "\n",
                "df = spark.read.parquet(\"s3://project-dev-wm/optimised/date_dim/full/202305231149/\")\n",
                "\n",
                "df.printSchema()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Union, Iterable\n",
                "from etl.addresses import Bucket\n",
                "\n",
                "def get_timestamp_of_most_recently_created_file(*, bucket_name:Union[Bucket,str], stem:str) -> str:\n",
                "    \"\"\"Return the most recent date in a subset of a bucket's file paths.\n",
                "\n",
                "    Args:\n",
                "        bucket_name (Bucket): The name of the bucket to search.\n",
                "        stem (str): The key of the file objects to search for.\n",
                "\n",
                "    Returns:\n",
                "        str: The most recent date in the bucket.\n",
                "\n",
                "    Raises:\n",
                "        ValueError: If no files are found in the bucket.\n",
                "        ValueError: If no dates are found in the bucket.\n",
                "    \"\"\"\n",
                "\n",
                "    bucket = boto3.resource('s3').Bucket(str(bucket_name))\n",
                "    bucket_objects:Iterable = bucket.objects\n",
                "\n",
                "    file_paths = [\n",
                "        obj\n",
                "        for obj\n",
                "        in bucket.objects.filter(Prefix=stem)\n",
                "    ]\n",
                "    \n",
                "    if not file_paths:\n",
                "        raise ValueError(\"No files found in bucket.\")\n",
                "\n",
                "    dates = []\n",
                "    for file in file_paths:\n",
                "        date_string = file.key.split('/')[-1].split('.')[0]\n",
                "        if date_string:\n",
                "            dates.append(date_string)\n",
                "\n",
                "    if not dates:\n",
                "        raise ValueError(\"No recent dates found in bucket.\")\n",
                "\n",
                "    return dates[-1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'part-00000-05a2301a-b24c-4a16-b10b-192246a7c843-c000'"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import boto3 \n",
                "get_timestamp_of_most_recently_created_file(bucket_name=Bucket.RAW, stem='raw/claim_db/policyholder/full/')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'get_latest_subdirectory' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_302824/1900297667.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mbucket_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"test-dev-wm\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raw/claim_db/claim/full/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mlatest_subdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_latest_subdirectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"The latest subdirectory under {prefix} is {latest_subdir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'get_latest_subdirectory' is not defined"
                    ]
                }
            ],
            "source": [
                "import boto3\n",
                "\n",
                "def get_lexicographically_highest_subdirectory(bucket_name, prefix):\n",
                "    \"\"\"\n",
                "    List all subdirectories under a prefix in an S3 bucket and return the \n",
                "    lexicographically highest.\n",
                "\n",
                "    Parameters:\n",
                "        bucket_name (str): The name of the S3 bucket.\n",
                "        prefix (str): The prefix (i.e., \"directory path\") to search under.\n",
                "\n",
                "    Returns:\n",
                "        str: The lexicographically highest subdirectory under the prefix.        \n",
                "    \"\"\"\n",
                "    s3 = boto3.resource('s3')\n",
                "    bucket = s3.Bucket(str(bucket_name))\n",
                "    \n",
                "    subdirs = set()\n",
                "    for obj in bucket.objects.filter(Prefix=prefix):\n",
                "        subdir = '/'.join(obj.key.split('/')[-2:])\n",
                "        subdirs.add(subdir)\n",
                "    \n",
                "    return max(subdirs) if subdirs else None\n",
                "\n",
                "# Usage\n",
                "bucket_name = \"test-dev-wm\"\n",
                "prefix = \"raw/claim_db/claim/full/\"\n",
                "latest_subdir = get_latest_subdirectory(bucket_name, prefix)\n",
                "print(f\"The latest subdirectory under {prefix} is {latest_subdir}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "# create an s3 folder in target bucket with a given prefix.`\n",
                "import boto3\n",
                "from datetime import datetime\n",
                "\n",
                "def create_s3_folder(bucket_name, prefix):\n",
                "    \"\"\"\n",
                "    Create an S3 folder with the given prefix in the given bucket.\n",
                "\n",
                "    Parameters:\n",
                "        bucket_name (str): The name of the S3 bucket.\n",
                "        prefix (str): The prefix (i.e., \"directory path\") to create.\n",
                "\n",
                "    Returns:\n",
                "        None\n",
                "    \"\"\"\n",
                "    s3 = boto3.resource('s3')\n",
                "    bucket = s3.Bucket(str(bucket_name))\n",
                "    bucket.put_object(Key=(prefix + f\"/{datetime.now().strftime('%Y%m%d%H%M')}\"))\n",
                "    \n",
                "bucket_name = 'demo-bucket-wmaz'\n",
                "prefix = '/scripts'\n",
                "\n",
                "create_s3_folder(bucket_name, prefix)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "3"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "3"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "import boto3\n",
                "\n",
                "def create_folder(bucket_name: str, folder_name: str):\n",
                "    s3 = boto3.resource('s3')\n",
                "    s3.Object(bucket_name, folder_name + '/').put()\n",
                "\n",
                "create_folder('demo-bucket-wmaz', 'my_folder')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'ResponseMetadata': {'RequestId': '264NJX0P3E6S30XC',\n",
                            "  'HostId': 'f2D299jfsY7m2Kux15Zj0CggcAXjh0Rnz3ATU/y13ILnpb/zeJnky/W5phnl+chRKSdX2EiGhyo=',\n",
                            "  'HTTPStatusCode': 200,\n",
                            "  'HTTPHeaders': {'x-amz-id-2': 'f2D299jfsY7m2Kux15Zj0CggcAXjh0Rnz3ATU/y13ILnpb/zeJnky/W5phnl+chRKSdX2EiGhyo=',\n",
                            "   'x-amz-request-id': '264NJX0P3E6S30XC',\n",
                            "   'date': 'Mon, 22 May 2023 11:48:13 GMT',\n",
                            "   'x-amz-server-side-encryption': 'AES256',\n",
                            "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
                            "   'server': 'AmazonS3',\n",
                            "   'content-length': '0'},\n",
                            "  'RetryAttempts': 1},\n",
                            " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
                            " 'ServerSideEncryption': 'AES256'}"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "s3 = boto3.resource('s3')\n",
                "s3.Object(\n",
                "    'raw-dev-wm', \n",
                "    f\"raw/claim_db/claim/full/{datetime.now().strftime('%Y%m%d%H%M')}\"\n",
                ").put(Body='')\n",
                "\n",
                "# delete the object\n",
                "s3.Object('raw-dev-wm', 'raw/claim_db/claim/full/202305211851').delete()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'ResponseMetadata': {'RequestId': '4NTT4QTT5ZNDEH4G',\n",
                            "  'HostId': '+Re7UqSEY1NJMULgzxffzQeQkO05auSLathgcukr+1siIw82Ia+UlfVkJLU+T33o7kg9xPAcIMs=',\n",
                            "  'HTTPStatusCode': 200,\n",
                            "  'HTTPHeaders': {'x-amz-id-2': '+Re7UqSEY1NJMULgzxffzQeQkO05auSLathgcukr+1siIw82Ia+UlfVkJLU+T33o7kg9xPAcIMs=',\n",
                            "   'x-amz-request-id': '4NTT4QTT5ZNDEH4G',\n",
                            "   'date': 'Mon, 22 May 2023 12:28:22 GMT',\n",
                            "   'x-amz-server-side-encryption': 'AES256',\n",
                            "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
                            "   'server': 'AmazonS3',\n",
                            "   'content-length': '0'},\n",
                            "  'RetryAttempts': 1},\n",
                            " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
                            " 'ServerSideEncryption': 'AES256'}"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "extreme_future_time = (\n",
                "        datetime(year=2999, month=1, day=1, hour=1, minute=1)\n",
                "            .strftime(\"%Y%m%d%H%M\")\n",
                "    )\n",
                "\n",
                "s3 = boto3.resource('s3')\n",
                "bucket_name = 'raw-dev-wm'\n",
                "object_key = f\"raw/claim_db/claim/full/{extreme_future_time}/\"\n",
                "\n",
                "object_key = f\"raw/claim_db/claim/full/{extreme_future_time}/\"\n",
                "s3.Object(bucket_name, object_key).put(Body='')\n",
                "\n",
                "# Clean up the mock S3\n",
                "# s3.Object(bucket_name, object_key).delete()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_lexicographically_highest_subdirectory(bucket_name, prefix) -> str:\n",
                "    \"\"\"\n",
                "    List all subdirectories under a prefix in an S3 bucket and return the \n",
                "    lexicographically highest.\n",
                "\n",
                "    Parameters:\n",
                "        bucket_name (str): The name of the S3 bucket.\n",
                "        prefix (str): The prefix (i.e., \"directory path\") to search under.\n",
                "\n",
                "    Returns:\n",
                "        str: The lexicographically highest subdirectory under the prefix.\n",
                "    \"\"\"\n",
                "    s3 = boto3.resource('s3')\n",
                "    bucket = s3.Bucket(str(bucket_name))\n",
                "    \n",
                "    subdirs = set()\n",
                "    for obj in bucket.objects.filter(Prefix=prefix):\n",
                "        subdir = '/'.join(obj.key.split('/')[-1:])\n",
                "        subdirs.add(subdir)\n",
                "    \n",
                "    return max(subdirs) + '/' if subdirs else 'did_not_work'"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "ImportError",
                    "evalue": "cannot import name 'output_path' from 'etl.jobs.access.provider' (/workspaces/ETL-TDD/etl/jobs/access/provider.py)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
                        "\u001b[0;32m/tmp/ipykernel_434300/603008960.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0metl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprovider\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;31mImportError\u001b[0m: cannot import name 'output_path' from 'etl.jobs.access.provider' (/workspaces/ETL-TDD/etl/jobs/access/provider.py)"
                    ]
                }
            ],
            "source": [
                "from pyspark.sql import SparkSession\n",
                "\n",
                "from etl.jobs.access.provider import input_path, output_path\n",
                "\n",
                "print(input_path)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-----------+--------------------+--------------------+---------------------+----------------------+--------------------+-----------------------+--------------------+--------------------+-----+--------+\n",
                        "|provider_id|       provider_name|             address|provider_phone_number|provider_email_address|       provider_type|provider_license_number|              street|              suburb|state|postcode|\n",
                        "+-----------+--------------------+--------------------+---------------------+----------------------+--------------------+-----------------------+--------------------+--------------------+-----+--------+\n",
                        "|     558433|        Cox and Sons|695 Ryan Nook, St...|      +61 2 4485 8099|  rmcdowell@example...|          Pharmacist|               82002543|       695 Ryan Nook|         St. Patrick|  VIC|    2697|\n",
                        "|     739426|        Dillon-Myers|606 Hamilton Circ...|      +61-3-9481-5525|    wmccoy@example.org|General Practitioner|               26265469| 606 Hamilton Circle|          Munozburgh|   NT|    2957|\n",
                        "|     849574|      Thompson-Silva|Apt. 486 646 Mich...|      +61-416-882-223|  jeremyfox@example...|          Specialist|               47912254|Apt. 486 646 Mich...| Lake Gabrielchester|  VIC|    2901|\n",
                        "|     631140|Fitzgerald, Moran...|Level 2 85 Rhonda...|         0446 612 209|  terrydeborah@exam...|     Physiotherapist|               79965027|Level 2 85 Rhonda...|           Jimmyfurt|  TAS|    2987|\n",
                        "|     945989|Morrison, Palmer ...|Flat 00 575 Erica...|         02-2869-3764|  matthewssamantha@...|          Specialist|               59185011|Flat 00 575 Erica...|       Elizabethbury|   NT|    9818|\n",
                        "+-----------+--------------------+--------------------+---------------------+----------------------+--------------------+-----------------------+--------------------+--------------------+-----+--------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "spark.read.parquet(input_path).show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "                                                                                \r"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "+-----------+--------------------+--------------------+---------------------+----------------------+--------------------+-----------------------+\n",
                        "|provider_id|       provider_name|    provider_address|provider_phone_number|provider_email_address|       provider_type|provider_license_number|\n",
                        "+-----------+--------------------+--------------------+---------------------+----------------------+--------------------+-----------------------+\n",
                        "|     558433|        Cox and Sons|695 Ryan Nook, St...|      +61 2 4485 8099|  rmcdowell@example...|          Pharmacist|               82002543|\n",
                        "|     739426|        Dillon-Myers|606 Hamilton Circ...|      +61-3-9481-5525|    wmccoy@example.org|General Practitioner|               26265469|\n",
                        "|     849574|      Thompson-Silva|Apt. 486 646 Mich...|      +61-416-882-223|  jeremyfox@example...|          Specialist|               47912254|\n",
                        "|     631140|Fitzgerald, Moran...|Level 2 85 Rhonda...|         0446 612 209|  terrydeborah@exam...|     Physiotherapist|               79965027|\n",
                        "|     945989|Morrison, Palmer ...|Flat 00 575 Erica...|         02-2869-3764|  matthewssamantha@...|          Specialist|               59185011|\n",
                        "+-----------+--------------------+--------------------+---------------------+----------------------+--------------------+-----------------------+\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "df.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def arguments(hi, hello):\n",
                "    a = 3\n",
                "    print(locals())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "{'hi': 'hi', 'hello': 'hello', 'a': 3}\n"
                    ]
                }
            ],
            "source": [
                "arguments('hi', 'hello')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 69,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'39990101010'"
                        ]
                    },
                    "execution_count": 69,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "s3 = boto3.resource('s3')\n",
                "bucket = s3.Bucket(str('raw-dev-wm'))\n",
                "prefix = 'raw/claim_db/claim/full/'\n",
                "\n",
                "candidate_dates = []\n",
                "for obj in bucket.objects.filter(Prefix=prefix):\n",
                "    \n",
                "    subdirs = obj.key.split('/')\n",
                "    leaf = subdirs[-2:][0]\n",
                "    if leaf.isdigit():\n",
                "        candidate_dates.append(leaf)\n",
                "        \n",
                "candidate_dates.append('39990101010')\n",
                "\n",
                "sorted(candidate_dates)[-1]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'s3://test-dev-wm/landing/claim_db/claim/full/202306211851/.csv'"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from etl.addresses import create_path\n",
                "from etl.addresses import Bucket, Source, Tier, Table, Environment, Load\n",
                "\n",
                "create_path(\n",
                "            environment=Environment.PROD,\n",
                "            bucket=Bucket.TEST,\n",
                "            tier=Tier.LANDING,\n",
                "            source=Source.CLAIM_DB,\n",
                "            table=Table.CLAIM,\n",
                "            load=Load.FULL,\n",
                "            time_required='recent',\n",
                "            file_extension='.csv'\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'202306211851'"
                        ]
                    },
                    "execution_count": 13,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from etl.addresses import get_timestamp_of_most_recently_created_file\n",
                "\n",
                "\n",
                "get_timestamp_of_most_recently_created_file(bucket_name=Bucket.TEST,stem='landing/claim_db/claim/full/')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.7.16"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}